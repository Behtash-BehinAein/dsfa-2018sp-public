{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 37: Enhancing Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plots\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plots.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "np.set_printoptions(legacy='1.13')\n",
    "\n",
    "NUM_REPETITIONS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ckd = Table.read_table('ckd.csv').relabeled('Blood Glucose Random', 'Glucose')\n",
    "    \n",
    "def ckd_label(number):\n",
    "    if number == 0:\n",
    "        return \"notckd\"\n",
    "    elif number == 1:\n",
    "        return \"ckd\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "  \n",
    "ckd = raw_ckd.with_column(\n",
    "    'Class', raw_ckd.apply(ckd_label, 'Class')\n",
    ")    \n",
    "ckd.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb_glc = ckd.select('Hemoglobin', 'Glucose', 'Class')\n",
    "hgb_glc.scatter('Hemoglobin', 'Glucose', colors='Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code for the classifier.**\n",
    "\n",
    "10 functions, 105 lines of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_units(array):\n",
    "    \"\"\"Convert array to standard units.\n",
    "    \"\"\"\n",
    "    return (array - array.mean()) / array.std()\n",
    "    \n",
    "def standardize(t):\n",
    "    \"\"\"Convert table t to standard units.\n",
    "    \"\"\"\n",
    "    su = Table()\n",
    "    for label in t.labels:\n",
    "        su = su.with_column(\n",
    "            label + ' (su)', standard_units(t.column(label))\n",
    "        )\n",
    "    return su\n",
    "\n",
    "def convert_table_with_classes_to_su(table):\n",
    "    \"\"\"Convert table to standard units.  The last column\n",
    "    of the table is assumed to be a non-quantitative \n",
    "    variable (i.e., a class) that should not be standardized.\n",
    "    \"\"\"\n",
    "    last_column_index = table.num_columns - 1\n",
    "    table_without_classes = table.drop(last_column_index)\n",
    "    table_without_classes_su = standardize(table_without_classes)\n",
    "    classes = table.column(last_column_index)\n",
    "\n",
    "    table_su = table_without_classes_su.with_column(\n",
    "        np.array(table.labels).item(last_column_index), classes\n",
    "    )\n",
    "\n",
    "    return table_su\n",
    "\n",
    "def in_su(value, array):\n",
    "    \"\"\"Return value in standard units according to \n",
    "    the distribution of array.\n",
    "    \"\"\"\n",
    "    return (value - array.mean()) / array.std()\n",
    "\n",
    "def new_point_in_su(new_point, table):\n",
    "    \"\"\"Return the new point, with all its coordinates converted\n",
    "    to standard units, according to the distribution given by\n",
    "    the table.  The first element of the new_point array \n",
    "    corresponds to the first column of the table, and so forth.\n",
    "    If the table has extra columns, they will be ignored.\n",
    "    \"\"\"\n",
    "    new_point_su = make_array()\n",
    "    num_dimensions = len(new_point)\n",
    "    for i in np.arange(num_dimensions):\n",
    "        coord_su = in_su(new_point.item(i), table.column(i))\n",
    "        new_point_su = np.append(new_point_su, coord_su)\n",
    "    return new_point_su\n",
    "\n",
    "def distance(a, b):\n",
    "    \"\"\"Returns the distance between a and b, where a and b\n",
    "    are both arrays representing points.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((a - b)**2))\n",
    "\n",
    "def all_distances(new_point, table):\n",
    "    \"\"\"Returns a table with two columns labeled Distance and Class.  \n",
    "    The first column contains the distance from new_point to each \n",
    "    point in table.  The second column contains the label of the \n",
    "    corresponding point in table.  The classes should be in the \n",
    "    final column of table.  The table that is returned is sorted in \n",
    "    ascending order by Distance.\n",
    "    \"\"\"\n",
    "\n",
    "    def distance_from_new(row):\n",
    "        \"\"\"Return the distance between row and new_point.\n",
    "        \"\"\"\n",
    "        return distance(np.array(row), new_point)\n",
    "\n",
    "    last_column_index = table.num_columns - 1\n",
    "    table_without_classes = table.drop(last_column_index)\n",
    "    classes = table.column(last_column_index)\n",
    "    \n",
    "    distances = Table().with_columns(\n",
    "        'Distance', table_without_classes.apply(distance_from_new),\n",
    "        'Class', classes\n",
    "    ).sort('Distance')\n",
    "\n",
    "    return distances\n",
    "\n",
    "def train_nn_su_classifier(train):\n",
    "    \"\"\"Create a nearest-neighbor classifier.  The last column \n",
    "    of the training table should be the labels, and the preceeding\n",
    "    columns should be the attributes.  The names of the columns do not\n",
    "    matter.  The classifier will work in standard units; but,\n",
    "    the training table should be in original units.\n",
    "    \n",
    "    Returns a function.  That function takes as input a \n",
    "    new point in original units. The function returns the \n",
    "    classification of the new point as output.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_su = convert_table_with_classes_to_su(train)\n",
    "    \n",
    "    def classify_new_point(new_point):\n",
    "        \"\"\"Return the classification of new_point, which\n",
    "        should still be in original units.\n",
    "        \"\"\"\n",
    "        new_point_su = new_point_in_su(new_point, train)\n",
    "        distances = all_distances(new_point_su, train_su)\n",
    "        return distances.column('Class').item(0)\n",
    "    \n",
    "    return classify_new_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** What is the type of `train_nn_su_classifier`?\n",
    "\n",
    "A.  a number  \n",
    "B.  an array  \n",
    "C.  a table  \n",
    "D.  a function  \n",
    "E.  none of the above  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_nn_su_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** What is the type of `train_nn_su_classifier(hgb_glc)`?\n",
    "\n",
    "A.  a number  \n",
    "B.  an array  \n",
    "C.  a table  \n",
    "D.  a function  \n",
    "E.  none of the above  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_nn_su_classifier(hgb_glc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** What is the type of `train_nn_su_classifier(hgb_glc)(make_array(15, 130))`?\n",
    "\n",
    "A.  a number  \n",
    "B.  an array  \n",
    "C.  a table  \n",
    "D.  a function  \n",
    "E.  none of the above  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_nn_su_classifier(hgb_glc)(make_array(15, 130)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = train_nn_su_classifier(hgb_glc)\n",
    "label = classifier(make_array(15, 130))\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions to analyze classifier accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_boundary(known_points, classifier, x_range, y_range):\n",
    "    \"\"\"Visualize the boundary region of a classifier.\n",
    "    The visualization is in original units.\"\"\"\n",
    "    decisions = Table(known_points.labels)\n",
    "    for x in x_range:\n",
    "        for y in y_range:\n",
    "            predicted = classifier(make_array(x, y))\n",
    "            decisions.append([x, y, predicted])\n",
    "    decisions.scatter(0, 1, colors='Class', alpha=0.4)\n",
    "    plots.xlim(x_range.min(), x_range.max())\n",
    "    plots.ylim(y_range.min(), y_range.max())\n",
    "    notckd_pts = known_points.where('Class', 'notckd')\n",
    "    ckd_pts = known_points.where('Class', 'ckd')\n",
    "    plots.scatter(notckd_pts.column(0), notckd_pts.column(1), c='gold', edgecolor='k');\n",
    "    plots.scatter(ckd_pts.column(0), ckd_pts.column(1), c='darkblue', edgecolor='k');\n",
    "\n",
    "def classifier_accuracy(test, classifier):\n",
    "    \"\"\"Evaluate the accuracy of the classifier using the\n",
    "    provided test table, whose last column should be\n",
    "    the labels.  The names of the columns are irrelevant.\"\"\"\n",
    "    \n",
    "    last_column = test.num_columns - 1\n",
    "    actual_labels = test.column(last_column)\n",
    "    predicted_labels = test.drop(last_column).apply(classifier)\n",
    "    \n",
    "    return np.mean(actual_labels == predicted_labels) \n",
    "\n",
    "def histogram_nn_classifier_accuracy(data, classifier_trainer, num_repetitions=NUM_REPETITIONS):\n",
    "    \"\"\"Visualize the empirical distribution of the accuracy\n",
    "    of a classifier.  The data input is a table that will\n",
    "    be split into test and training tables for each iteration\n",
    "    The classifier_trainer is a function that takes a training \n",
    "    table as input, and returns a classifier function.  That \n",
    "    classifier function itself should take a new point as input \n",
    "    and return the classification of that point.\"\"\"\n",
    "\n",
    "    accuracies = make_array()\n",
    "    \n",
    "    for _ in np.arange(num_repetitions):\n",
    "        half = int(data.num_rows / 2)\n",
    "        train, test = data.split(half) \n",
    "        \n",
    "        trained_classifier = classifier_trainer(train)\n",
    "        acc = classifier_accuracy(test, trained_classifier)\n",
    "        accuracies = np.append(accuracies, acc)\n",
    "    \n",
    "    Table().with_column(\n",
    "        'Accuracy', accuracies\n",
    "    ).hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_nn_classifier_accuracy(hgb_glc, train_nn_su_classifier, num_repetitions=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Majority Voting in a Neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to a pair of variables where it was harder to classify..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd.scatter('White Blood Cell Count', 'Glucose', colors='Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd.scatter('White Blood Cell Count', 'Glucose', colors='Class')\n",
    "plots.xlim(3500,10000);\n",
    "plots.ylim(60,180);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbc_glc = ckd.select('White Blood Cell Count', 'Glucose', 'Class')\n",
    "half = int(wbc_glc.num_rows / 2)\n",
    "train_wbc_glc, test_wbc_glc = wbc_glc.split(half)\n",
    "wbc_glc_scaled_classifier = train_nn_su_classifier(train_wbc_glc)\n",
    "visualize_boundary(train_wbc_glc, wbc_glc_scaled_classifier,\n",
    "                  np.arange(3500,11000,200), np.arange(60,200,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** How many points are being mis-classified here?\n",
    "\n",
    "A. 0  \n",
    "B. 1  \n",
    "C. 2 or more  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_accuracy(train_wbc_glc, wbc_glc_scaled_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_boundary(test_wbc_glc, wbc_glc_scaled_classifier,\n",
    "                  np.arange(3500,11000,200), np.arange(60,200,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** How many points are being mis-classified here?\n",
    "\n",
    "A. 0  \n",
    "B. 1  \n",
    "C. 2 or more  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_accuracy(test_wbc_glc, wbc_glc_scaled_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_nn_classifier_accuracy(wbc_glc, train_nn_su_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent_value(array):\n",
    "    \"\"\"Returns the value of array that occurs most frequently.\n",
    "    \"\"\"\n",
    "    t = Table().with_column('values', array)\n",
    "    counts = t.group('values').sort('count', descending=True).column('values')\n",
    "    return counts.item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_value(make_array(1,1,1,0,0,0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn_su_classifier(train, k):\n",
    "    \"\"\"Create a k-nearest-neighbor classifier.  The last column \n",
    "    of the training table should be the labels, and the preceeding\n",
    "    column should be the attributes.  The names of the columns do not\n",
    "    matter.  The classifier will work in standard units; but,\n",
    "    the training table should be in original units.    \n",
    "    \n",
    "    Returns a function.  That function takes as input a \n",
    "    new point, which should be an array with two items,\n",
    "    the x and y value of the new point, in that order,\n",
    "    in original units. The function returns the \n",
    "    classification of the new point as output.\"\"\"\n",
    "\n",
    "    train_su = convert_table_with_classes_to_su(train)\n",
    "    \n",
    "    def classify_new_point(new_point):\n",
    "        \"\"\"Return the classification of new_point, which\n",
    "        should still be in original units.\n",
    "        \"\"\"\n",
    "        new_point_su = new_point_in_su(new_point, train)\n",
    "        distances = all_distances(new_point_su, train_su)\n",
    "        top_k = distances.take(np.arange(k)).column('Class')\n",
    "        return most_frequent_value(top_k)\n",
    "    \n",
    "    return classify_new_point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_visualize_wbc_glc(k):\n",
    "    classifier = train_knn_su_classifier(train_wbc_glc, k)\n",
    "    visualize_boundary(test_wbc_glc, classifier,\n",
    "                  np.arange(3500,11000,250), np.arange(60,200,10))\n",
    "    acc = classifier_accuracy(test_wbc_glc, classifier)\n",
    "    print('Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_visualize_wbc_glc(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_visualize_wbc_glc(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_visualize_wbc_glc(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_knn_classifier_accuracy(data, classifier_trainer, k=5, num_repetitions=NUM_REPETITIONS):\n",
    "    \"\"\"Visualize the empirical distribution of the accuracy\n",
    "    of a classifier.  The data input is a table that will\n",
    "    be split into test and training tables for each iteration\n",
    "    The classifier_trainer is a function that takes a training \n",
    "    table as input, and returns a classifier function.  That \n",
    "    classifier function itself should take a new point as input \n",
    "    and return the classification of that point.\"\"\"\n",
    "\n",
    "    accuracies = make_array()\n",
    "    \n",
    "    for _ in np.arange(num_repetitions):\n",
    "        half = int(data.num_rows / 2)\n",
    "        train, test = data.split(half)\n",
    "        \n",
    "        trained_classifier = classifier_trainer(train, k)\n",
    "        acc = classifier_accuracy(test, trained_classifier)\n",
    "        accuracies = np.append(accuracies, acc)\n",
    "    \n",
    "    Table().with_column(\n",
    "        'Accuracy', accuracies\n",
    "    ).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in make_array(1,3,5):\n",
    "    histogram_knn_classifier_accuracy(wbc_glc, train_knn_su_classifier, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with multiple attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With CKD we could find one pair of attributes with a clean separation boundary.  What if we couldn't?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://archive.ics.uci.edu/ml/datasets/banknote+authentication\n",
    "banknotes = Table.read_table('banknote.csv')\n",
    "banknotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banknotes.scatter('WaveletVar', 'WaveletCurt', colors='Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banknotes.scatter('WaveletSkew', 'Entropy', colors='Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plots.figure()\n",
    "ax = plots.axes(projection='3d')\n",
    "ax.scatter(banknotes.column('WaveletSkew'), \n",
    "           banknotes.column('WaveletVar'), \n",
    "           banknotes.column('WaveletCurt'), \n",
    "           c=banknotes.column('Class'),\n",
    "           cmap='viridis',\n",
    "          s=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance(make_array(0,0), make_array(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance(make_array(0,0,0), make_array(1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance(make_array(0,0,0,0), make_array(1,1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_knn_classifier_accuracy(\n",
    "    banknotes.select('WaveletVar', 'WaveletSkew', 'Class'), \n",
    "    train_knn_su_classifier, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_knn_classifier_accuracy(\n",
    "    banknotes.select('WaveletVar', 'WaveletSkew', 'WaveletCurt', 'Class'), \n",
    "    train_knn_su_classifier, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
